---
title: 'Saldana, Montano, et al. -- 11 ATAC-seq: Annotation and enrichment analysis' 
author: 'Florian Halbritter and Luis Montano'
date: '`r format(Sys.time(), "%B %d, %Y %H:%M:%S %Z")`'
output:
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: show
    highlight: pygments
    df_print: paged
params:
  seurat_max_pc: 15
  seurat_cluster_res: 0.3
  seurat_metric: manhattan
  seurat_k_param: 20
  seurat_n_neighbors: 40
  inputdata: '~/path/to/input_data/'
  plotpath: '~/path/to/plots/'
  cachedir: '~/path/to/cachedir/'
  outpath: '~/mnt_out/figures/'
  resourcepath: "~/mnt_resources/"
  gtfpath: '~/path/to/gencode.v40.annotation.gtf.gz'
  downloadedfilepath: '~/path/to/downloaded_files/'
---

# Analysis of the extended dataset containing many additional genotypes, obtained by split pool combinatorial barcoding

## Figures addressed in this script:

Supplementary figure 7 c
Supplementary figure 7 d

## Dependencies

This script depends on scrna/04 to to perform the mapping of parse cells to the wt clusters (several inputs) 


```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir = '/home/rstudio/')

```

Load utility scripts, constants, etc. used throughput the project:

```{r, include=FALSE}

source("~/R/importdata.R")

source("~/R/setup_parse2.R")

library('canceRbits')
library('patchwork')
library('Seurat')
library('tidyverse')
library('simpleCache')


results_dir <- file.path(config$out_root, "parse")
parse_pipe_dir <- file.path(config$out_root, "parse", "parse_pipe", "Parse_combined")

includestages="D9"


```



```{r}

all.parse.matrix.paths=grep(".html|.log|process|.csv|all-well|.zip", dir(parse_pipe_dir, full.names = T), value = T, invert = T)

subsample.names=lapply(strsplit(all.parse.matrix.paths, split="/"), function(x) x[length(x)])

finaldir=params$out

 lapply(1:length(all.parse.matrix.paths), function(yy){ paste0("cp ", all.parse.matrix.paths[[yy]], "/DEG.mtx ", finaldir, "DEG_", subsample.names[[yy]], ".mtx\n")})


```

Show parameters:

```{r}
print(params)
```

Define functions to read and interpret parse datasets:

```{r def_parse_funcs}
# ReadMtx in Seurat5 beta lacks the feature.sep parameter etc., so we override it with the old one from
# https://raw.githubusercontent.com/satijalab/seurat/763259d05991d40721dee99c9919ec6d4491d15e/R/preprocessing.R:
# (commented out a few unnecessary parts using Seurat-internal functions)
ReadMtx <- function(
  mtx,
  cells,
  features,
  cell.column = 1,
  feature.column = 2,
  cell.sep = "\t",
  feature.sep = "\t",
  skip.cell = 0,
  skip.feature = 0,
  mtx.transpose = FALSE,
  unique.features = TRUE,
  strip.suffix = FALSE
) {
  all.files <- list(
    "expression matrix" = mtx,
    "barcode list" = cells,
    "feature list" = features
  )
  for (i in seq_along(along.with = all.files)) {
    uri <- tryCatch(
      expr = {
        con <- url(description = all.files[[i]])
        close(con = con)
        all.files[[i]]
      },
      error = function(...) {
        return(normalizePath(path = all.files[[i]], winslash = '/'))
      }
    )
    err <- paste("Cannot find", names(x = all.files)[i], "at", uri)
    if (grepl(pattern = '^[A-Z]?:///', x = uri)) {
      uri <- gsub(pattern = '^://', replacement = '', x = uri)
      if (!file.exists(uri)) {
        stop(err, call. = FALSE)
      }
    } else {

      if (grepl('gz$', uri)) {
        con <- url(description = uri)
        uri <- gzcon(con = con, text = TRUE)
      }
    }
    all.files[[i]] <- uri
  }
  cell.barcodes <- read.table(
    file = all.files[['barcode list']],
    header = FALSE,
    sep = cell.sep,
    row.names = NULL,
    skip = skip.cell
  )
  feature.names <- read.table(
    file = all.files[['feature list']],
    header = FALSE,
    sep = feature.sep,
    row.names = NULL,
    skip = skip.feature
  )
  # read barcodes
  bcols <- ncol(x = cell.barcodes)
  if (bcols < cell.column) {
    stop(
      "cell.column was set to ",
      cell.column,
      " but ",
      cells,
      " only has ",
      bcols,
      " columns.",
      " Try setting the cell.column argument to a value <= to ",
      bcols,
      "."
    )
  }
  cell.names <- cell.barcodes[, cell.column]
  if (all(grepl(pattern = "\\-1$", x = cell.names)) & strip.suffix) {
    cell.names <- as.vector(x = as.character(x = sapply(
      X = cell.names,
      FUN = ExtractField,
      field = 1,
      delim = "-"
    )))
  }
  # read features
  fcols <- ncol(x = feature.names)
  if (fcols < feature.column) {
    stop(
      "feature.column was set to ",
      feature.column,
      " but ",
      features,
      " only has ",
      fcols, " column(s).",
      " Try setting the feature.column argument to a value <= to ",
      fcols,
      "."
    )
  }
  if (any(is.na(x = feature.names[, feature.column]))) {
    na.features <- which(x = is.na(x = feature.names[, feature.column]))
    replacement.column <- ifelse(test = feature.column == 2, yes = 1, no = 2)
    if (replacement.column > fcols) {
      stop(
        "Some features names are NA in column ",
        feature.column,
        ". Try specifiying a different column.",
        call. = FALSE
        )
    } else {
      warning(
        "Some features names are NA in column ",
        feature.column,
        ". Replacing NA names with ID from column ",
        replacement.column,
        ".",
        call. = FALSE
        )
    }
    feature.names[na.features, feature.column] <- feature.names[na.features, replacement.column]
  }
  feature.names <- feature.names[, feature.column]
  if (unique.features) {
    feature.names <- make.unique(names = feature.names)
  }
  data <- Matrix::readMM(file = all.files[['expression matrix']])
  if (mtx.transpose) {
    data <- Matrix::t(x = data)
  }
  if (length(x = cell.names) != ncol(x = data)) {
    stop(
      "Matrix has ",
      ncol(data),
      " columns but found ", length(cell.names),
      " barcodes. ",
      ifelse(
        test = length(x = cell.names) > ncol(x = data),
        yes = "Try increasing `skip.cell`. ",
        no = ""
      ),
      call. = FALSE
      )
  }
  if (length(x = feature.names) != nrow(x = data)) {
    stop(
      "Matrix has ",
      nrow(data),
      " rows but found ", length(feature.names),
      " features. ",
      ifelse(
        test = length(x = feature.names) > nrow(x = data),
        yes = "Try increasing `skip.feature`. ",
        no = ""
      ),
      call. = FALSE
      )
  }

  colnames(x = data) <- cell.names
  rownames(x = data) <- feature.names
  data <- as.sparse(x = data)
  return(data)
}

loadParseSample <- function(path, sample_name=basename(path)) {
    message(sample_name)
    
    curDataDir <- file.path(path, "DGE_filtered")
    
    mat <- (ReadMtx(mtx = file.path(curDataDir, "DGE.mtx"), cells = file.path(curDataDir, "cell_metadata.csv"), features = file.path(curDataDir, "all_genes.csv"), 
          cell.column = 1, feature.column = 2, cell.sep = ",", 
          feature.sep = ",", skip.cell = 1, skip.feature = 1, mtx.transpose = TRUE))

    # Read in cell meta data
    cellMeta <- read.csv(file.path(curDataDir, "cell_metadata.csv"), row.names = 1)
    
    so <- CreateSeuratObject(mat, min_genes = 100, min_cells = 0, names.field = 0, meta.data = cellMeta, project =sample_name)
  
    return(so)
}

loadParseSamples <- function(parent_path, sample_names, n_threads=min(config$n_threads_max, length(sample_names))) {
  msgF("Read in %d samples (using %d threads)...", length(sample_names), n_threads)
  
  soList <- parallel::mclapply(X=sample_names, FUN=function(sample_name) {
    sample_name=gsub("_17qm_", "_17q_", sample_name)  # patch a mistake in the sample names which do not match the folder names for 17qm
    so <- loadParseSample(file.path(parent_path, sample_name), sample_name)
    msgF("\t- %s done", sample_name)
    return(so)
  }, mc.cores=n_threads)
  names(soList) <- names(sample_names)
  
  msgF("Merge %d individual Seurat objects...", length(soList))
  fcat("class of solist:", class(soList))
  
  if(length(soList)>1) {
    fcat("length is more than one")
    so <- merge(x = soList[[1]], y = soList[-1], add.cell.ids = names(soList), project = "ncnb_parse")
  }else{
   
    so <- soList[[1]]
  }
  
  return(so)
}

```

# Read metadata

```{r add_parse_meta}
meta <- data.table::fread(paste0(params$workdir, "/metadata/samples_parse.csv"))  %>% mutate(condition=paste0("c", condition), pipe_name=gsub("_17qm_", "_17q_", sample_name))
data.table::setkey(meta, "pipe_name")

print(meta)

ctsday=meta %>% as.data.frame %>% group_by(parental, condition, day) %>% summarise(counts=n()) %>% as.data.frame
```

#load sample metadata table, ready to go

Select samples to work with. Example: All H9-derived data at D9

```{r select_meta_example}
simpleCache("parse_samples_reference_table", {
cts=meta %>% as.data.frame %>% group_by(parental, condition) %>% summarise(counts=n())
cts}, reload=T, assignToVar="cts")


gentable.filtered=gentable %>% filter(stage %in% includestages) %>% group_by(actual.cgenotype, parental) %>% summarise(counts=n())
simpleCache("parse_samples_genotype_table_actualgenotypescorrected", {gentable.filtered}, assignToVar="gentable.filtered", reload=T)

meta[["condition"]]=gsub( "cMYCN", "cWTMYCN", meta[["condition"]])

simpleCache("parse_sample_metadata_actualgenotypescorrected_newrepnames", {
meta2=meta %>% mutate(actual.cgenotype=get.actual.genotype(condition)  , new_rep=adapt.rep(condition, actual.cgenotype, rep_num))
meta2
}, assignToVar="meta2", reload=T)
```

# Apply basic processing to all parse subsamples, including finding markers for parse cells mapped to every subgroup of the WT dataset. 

```{r select_meta_example}
all.selected.meta=list()
alltopmarkers=list()
allcellinfos=list()
allmarkers=list()
allheatmaps=list()


recreate.processing=T
recreate.filtering=F
recreate.markers=T
recreate.heatmap=T


for(i in 1:nrow(gentable.filtered)){
p=gentable.filtered[i, "parental"] %>% as.character
cond=gentable.filtered[i, "actual.cgenotype"] %>% as.character
  
selectedMeta <-  meta2 %>% filter(parental==p, actual.cgenotype==cond)
print(selectedMeta)

all.selected.meta[[i]]=selectedMeta

################################################################################
#Basic processing of parse data together with finding markers for each group of
#cells triaged to the wild type clusters. 
################################################################################

simpleCache(paste_("so_parse_selected_processed_mappedWTmarkers", p, cond),{

simpleCache(paste_("so_parse_selected_processed", p, cond),{
  gc()

simpleCache(paste_("so_parse_filtered", p, cond),{
   gc()
simpleCache(paste_("so_parse_raw", p, cond),{ 
  fcat("creating raw seurat...")
   gc()
so <- loadParseSamples(parse_pipe_dir, selectedMeta$sample_name, n_threads=1)
so@meta.data <- cbind(so@meta.data, as.data.frame(meta2[as.character(so@meta.data$orig.ident),])) # add metadata from 
so
}, assignToVar="so",reload=T)

print(so)
fcat("filtering seurat with standard pipeline...")

#Apply standard quality control (also very fast):

tmp <- cb_filter_count_matrix(counts = so@assays$RNA@counts, sample_id = paste(selectedMeta$sample_name, collapse=", "))
tmp$filtered@meta.data <- cbind(tmp$filtered@meta.data, so@meta.data[colnames(tmp$filtered), setdiff(colnames(so@meta.data), colnames(tmp$filtered@meta.data))]) # add extra metadata from `so` back to `tmp$filtered`
print(wrap_plots(tmp$figures) + plot_annotation(title = tmp$fig_title))
so <- tmp$filtered

so
}, assignToVar="so",recreate=recreate.filtering, reload=!recreate.filtering)

#Run through standard Seurat pipeline (this part can take a while, if many samples are included):

fcat("processing seurat with standard pipeline...")
tmp <- cb_seurat_pipeline(so, 
                        max_pc = params$seurat_max_pc,
                        metric = params$seurat_metric, 
                        k_param = params$seurat_k_param, 
                        n_neighbors = params$seurat_n_neighbors,
                        cluster_res = params$seurat_cluster_res)
so <- tmp$s
so
}, assignToVar="so", recreate=recreate.processing, reload=!recreate.processing)


################################################################################
# get seurat markers based on mapping
################################################################################
 percent.mt<- PercentageFeatureSet(so, pattern = "^MT-") %>% givecolnames(., nms="percent.mt")
 so@meta.data= cbind(so@meta.data,  percent.mt)

 fcat("incorporating mapping metadata...")
 mappedcells.df= mapdf.gencorrected %>% filter(actual.cgenotype==!!cond, parental==!!p, stage %in% includestages) 
  mappedcells= mappedcells.df %>% rownames

  fcat("num cells in filtered dataset:", so@meta.data %>% nrow )
  fcat("num mapped cells:", length(mappedcells))
  
  
  cellintersect=intersect(mappedcells, so@meta.data %>% rownames)
  
  fcat("num cells both mapped and in dataset:", length(cellintersect))
  
  so= so[, cellintersect ]
  so@meta.data=cbind(so@meta.data, mappedcells.df[cellintersect,]) 
  so@meta.data= so@meta.data[,!(so %>% metadata %>% colnames %>% duplicated)]

 markers.var="WT.clusters"
  
 cluslabel=mapfun(markers.var)
options(future.globals.maxSize = 2 * 10^9)
fullreload=F; fullrecreate=T
datte="2023-12-29" #if running a new version replace this by 'chopstring(timestamp(""))
verbose=F
meth="deseq"
smeth="seurat"
groupvar="group1"
pvar="padj"
thresh=pval
fcvar="log_fc"
minrate=.5
minfc=1
predicted.id.thresh=0.6
replicatecol=NULL
pastedstages=paste0(includestages, collapse="-")
Project(so)=paste0("parse-", p,"-", cond, "-", includestages)
filterps(so, varbl=markers.var, th=predicted.id.thresh) 
fcat("num high quality mapped cells:", 
filterps(so, varbl=markers.var, th=predicted.id.thresh) %>% ncol )
  fcat("calculating markers for mapped cells using delegate...") 
so=seuratmarkers.delegate(filterps(so, varbl=markers.var, th=predicted.id.thresh), group_column=mapfun(markers.var), replicate_column=replicatecol, minfc=minfc, selecttop=selecttop, method=method.markers, getresidual=F, fullreload=F, fullrecreate=T, minrate=minrate, min.cells.per.group=10)

alltopmarkers[[i]]=get.top.markers(so)
allmarkers[[i]]=get.markers(so)

simpleCache(paste_("cellinfo_parse", p, cond), {
 
  fcat("seriating cells/making cellinfo") 
  cellinfo= seriatecells(so, clusvar=mapfun(markers.var), meth=smeth, clusters=allcolors[[markers.var]] %>% names  ,groupvarname=groupvar,lfcvarname=fcvar, extended.output=T, deduped=T, ncells=500)
cellinfo}, assignToVar="cellinfo", recreate=T)

fcat("assigning cellinfo to global")
allcellinfos[[i]]=cellinfo

heatmap.info=NULL

ci=allcellinfos[[i]]
gtl= adjust.markers(ci, 7)$markers

simpleCache(paste0("heatmap_info_", Project(so)),{ 
  allheatmaps[[i]]=cellinfo.heatmap(so, cellinfo = allcellinfos[[i]], genes.to.label = gtl, assay="SCT", return.everything=T, name=Project(so), colorlist=allcolors) 
allheatmaps[[i]]          
}, assignToVar="heatmap.info", recreate=recreate.heatmap)
allheatmaps[[i]]=heatmap.info
heatmap.info=NULL

################################################################################
# create heatmap
################################################################################

sca=1.6
tpdf(path=params$plotpath, paste0("p2",i,"heatmap_parse", p, cond), wi=pw*sca*1.3, he=pw*sca)
print(allheatmaps[[i]]$heatmap)
dev.off()
rm(cellinfo)


gc()

so
  }, assignToVar="so", recreate=recreate.markers)

}
gc()

```

process only day 9

```{r}

for(i in 1:nrow(gentable.filtered)){
p=gentable.filtered[i, "parental"] %>% as.character
cond=gentable.filtered[i, "actual.cgenotype"] %>% as.character
  
selectedMeta <-  meta2 %>% filter(parental==p, actual.cgenotype==cond, stage %in% includestages)
print(selectedMeta)

all.selected.meta[[i]]=selectedMeta

## Basic processing

#Read in Parse data (this part is quite fast):
simpleCache(paste_("so_parse_selected_processed", p, cond, includestages),{
  gc()
  
so <- loadParseSamples(parse_pipe_dir, selectedMeta$sample_name, n_threads=1)
so@meta.data <- cbind(so@meta.data, as.data.frame(meta[as.character(so@meta.data$orig.ident),])) # add metadata from sample annotation sheet
print(so)


#Apply standard quality control (also very fast):

tmp <- cb_filter_count_matrix(counts = so@assays$RNA@counts, sample_id = paste(selectedMeta$sample_name, collapse=", "))
tmp$filtered@meta.data <- cbind(tmp$filtered@meta.data, so@meta.data[colnames(tmp$filtered), setdiff(colnames(so@meta.data), colnames(tmp$filtered@meta.data))]) # add extra metadata from `so` back to `tmp$filtered`
print(wrap_plots(tmp$figures) + plot_annotation(title = tmp$fig_title))
so <- tmp$filtered


#Run through standard Seurat pipeline (this part can take a while, if many samples are included):

tmp <- cb_seurat_pipeline(so, 
                        max_pc = params$seurat_max_pc,
                        metric = params$seurat_metric, 
                        k_param = params$seurat_k_param, 
                        n_neighbors = params$seurat_n_neighbors,
                        cluster_res = params$seurat_cluster_res)
so <- tmp$s
so
}, assignToVar="so", recreate=T)
rm(so)
gc()
  }


```

## code to process and find markers for clusters of individual datasets of conditions


the purpose of this block is to assemble marker data and cell data for several conditions in central objects called allheatmaps and allcellinfos. 

These objects will be used downstream. 


```{r}
conds=c("c17q1q_H7", "c17q1q_H9", "c17q1qMYCN_H7", "c17q1qMYCN_H9", 
"c17qm_H7", "c17qMYCN_H7", "cWT_H7", "cWT_H9", "cWTm_H7", "cWTMYCN_H7"
)
includestages="D9"
datte.parse="20230103-1"
ncells=2000
predicted.id.thresh=0.4
all.selected.meta=list()
alltopmarkers=list()
allcellinfos=list()
allmarkers=list()
allheatmaps=list()
allmetadatas=list()
recreate.processing=F
recreate.filtering=F
recreate.markers=F
recreate.heatmap=T
for(i in 1:nrow(gentable.filtered)){
p=gentable.filtered[i, "parental"] %>% as.character
cond=gentable.filtered[i, "actual.cgenotype"] %>% as.character
selectedMeta <-  meta2 %>% filter(parental==p, actual.cgenotype==cond)
print(selectedMeta)
all.selected.meta[[i]]=selectedMeta
## Basic processing
#Read in Parse data (this part is quite fast):



simpleCache(paste_("so_parse_selected_processed_mappedWTmarkers", p, cond, "pidthresh",predicted.id.thresh, "version", datte.parse),{
simpleCache(paste_("so_parse_selected_processed", p, cond),{
gc()
simpleCache(paste_("so_parse_filtered", p, cond),{
gc()
simpleCache(paste_("so_parse_raw", p, cond),{
fcat("creating raw seurat...")
gc()
so <- loadParseSamples(parse_pipe_dir, selectedMeta$sample_name, n_threads=1)
so@meta.data <- cbind(so@meta.data, as.data.frame(meta2[as.character(so@meta.data$orig.ident),])) # add metadata from
so
}, assignToVar="so",reload=T)



print(so)
fcat("filtering seurat with standard pipeline...")
#Apply standard quality control (also very fast):
tmp <- cb_filter_count_matrix(counts = so@assays$RNA@counts, sample_id = paste(selectedMeta$sample_name, collapse=", "))
tmp$filtered@meta.data <- cbind(tmp$filtered@meta.data, so@meta.data[colnames(tmp$filtered), setdiff(colnames(so@meta.data), colnames(tmp$filtered@meta.data))]) # add extra metadata from `so` back to `tmp$filtered`
print(wrap_plots(tmp$figures) + plot_annotation(title = tmp$fig_title))
so <- tmp$filtered
so
}, assignToVar="so",recreate=recreate.filtering, reload=!recreate.filtering)


#Run through standard Seurat pipeline (this part can take a while, if many samples are included):
fcat("processing seurat with standard pipeline...")
tmp <- cb_seurat_pipeline(so,
max_pc = params$seurat_max_pc,
metric = params$seurat_metric,
k_param = params$seurat_k_param,
n_neighbors = params$seurat_n_neighbors,
cluster_res = params$seurat_cluster_res)
so <- tmp$s
so
}, assignToVar="so", recreate=recreate.processing, reload=!recreate.processing)
  
  
################################################################################
# get seurat markers based on mapping
################################################################################
  
  
percent.mt<- PercentageFeatureSet(so, pattern = "^MT-") %>% givecolnames(., nms="percent.mt")
so@meta.data= cbind(so@meta.data,  percent.mt)
fcat("incorporating mapping metadata...")
mappedcells.df= mapdf.gencorrected %>% filter(actual.cgenotype==!!cond, parental==!!p, stage %in% includestages)
mappedcells= mappedcells.df %>% rownames


fcat("num cells in filtered dataset:", so@meta.data %>% nrow )
fcat("num mapped cells:", length(mappedcells))
cellintersect=intersect(mappedcells, so@meta.data %>% rownames)
fcat("num cells both mapped and in dataset:", length(cellintersect))
so= so[, cellintersect ]
so@meta.data=cbind(so@meta.data, mappedcells.df[cellintersect,])
so@meta.data= so@meta.data[,!(so %>% metadata %>% colnames %>% duplicated)]
markers.var="WT.clusters"
cluslabel=mapfun(markers.var)
options(future.globals.maxSize = 2 * 10^9)
fullreload=F; fullrecreate=T
datte="2023-12-29" #chopstring(timestamp(""))
verbose=F
meth="deseq"
smeth="seurat"
groupvar="group1"
pvar="padj"
thresh=pval
fcvar="log_fc"
minrate=.5
minfc=1

replicatecol=NULL
pastedstages=paste0(includestages, collapse="-")
Project(so)=paste0("parse-", p,"-", cond, "-", includestages)
filterps(so, varbl=markers.var, th=predicted.id.thresh)
fcat("num high quality mapped cells:",
filterps(so, varbl=markers.var, th=predicted.id.thresh) %>% ncol )
fcat("calculating markers for mapped cells using delegate...")
so=seuratmarkers.delegate(filterps(so, varbl=markers.var, th=predicted.id.thresh), group_column=mapfun(markers.var), replicate_column=replicatecol, minfc=minfc, selecttop=selecttop, method=method.markers, getresidual=F, fullreload=F, fullrecreate=T, minrate=minrate, min.cells.per.group=10)
so
}, assignToVar="so", recreate=recreate.markers)
simpleCache(paste_("cellinfo_parse", p, cond, "pthreshold",predicted.id.thresh, "ncells", ncells, "version", datte.parse), {
fcat("seriating cells/making cellinfo")
cellinfo= seriatecells(so, clusvar=mapfun(markers.var), meth=smeth, clusters=allcolors[[markers.var]] %>% names  ,groupvarname=groupvar,lfcvarname=fcvar, extended.output=T, deduped=T, ncells=ncells)
cellinfo}, assignToVar="cellinfo", recreate=T)

fcat("assigning cellinfo to global")
allcellinfos[[i]]=cellinfo
heatmap.info=NULL
ci=allcellinfos[[i]]
gtl= adjust.markers(ci, 7)$markers
simpleCache(paste0("heatmap_info_", Project(so)),{
allmetadatas[[i]]=metadata(so)
alltopmarkers[[i]]=get.top.markers(so)
allmarkers[[i]]=get.markers(so)
allheatmaps[[i]]=cellinfo.heatmap(so, cellinfo = allcellinfos[[i]], genes.to.label = gtl, assay="SCT", return.everything=T, name=Project(so), colorlist=allcolors)
allheatmaps[[i]]
}, assignToVar="heatmap.info", recreate=recreate.heatmap)
allheatmaps[[i]]=heatmap.info
heatmap.info=NULL
################################################################################
# create heatmap
################################################################################
sca=1.6
tpdf(path=params$plotpath, paste0("p2",i,"heatmap_parse", p, cond), wi=pw*sca*1.3, he=pw*sca)
print(allheatmaps[[i]]$heatmap)
dev.off()
rm(cellinfo)
gc()
}
gc()
```

store temp info objects from above
```{r}

predicted.id.thresh=0.4
parseid=paste0("mappedcells_day9_", "allcells", "_filtermapped_", predicted.id.thresh, "version_", datte.parse)

simpleCache(paste_("allmetadatas", parseid), {
  names(allmetadatas)=conds
  allmetadatas}, assignToVar="allmetadatas", reload=T)
simpleCache(paste_("allcellinfos", parseid), {
  names(allcellinfos)=conds
  allcellinfos}, assignToVar="allcellinfos", reload=T)
simpleCache(paste_("allheatmaps", parseid), {
  names(allheatmaps)=conds
  allheatmaps}, assignToVar="allheatmaps", reload=T)

## updated mapdf information with conditionclusters and pcondition among other things.

mapdf.gc3=mapdf.gencorrected %>% mutate(pcondition=paste_(actual.cgenotype, parental))
simpleCache("parse_mapdf_corrected_additional_info",{ mapdf.gc3}, assignToVar="mapdf.gc3", reload=T)


samples=lapply(1:length(allmetadatas), function(x){
allmetadatas[[x]]$sample_name
}) %>% Reduce(c, .) %>% unique

allcells=lapply(1:length(allcellinfos), function(x){
allcellinfos[[x]]$cells
}) %>% Reduce(c, .) %>% unique


selectedMeta <-  meta2 %>% filter(sample_name %in% !!samples)

allcells=mapdf.gc3 %>% filter(stage %in% includestages, mapfun_WT.clusters_predicted.id.score>=predicted.id.thresh) %>% rownames

allcellmetadata=lapply(1:length(allmetadatas), function(x){
allmetadatas[[x]]
}) %>% Reduce(rbind, .)

metadatamapped=allcellmetadata[allcells, ]


fwrite(metadatamapped, file=file.path(params$outpath, paste0("figuredata_parse_mapping_metadata_hq_mapping_above_", predicted.id.thresh, "_version", datte.parse,".csv")))

```


Supplementary figure 7 c

```{r}
sca=0.6
tpdf(path=params$outpath, "transferplot_parse", wi=pw*sca, he=pw*sca)
transferplot(df=mapdf.gencorrected,so=NULL,  labelvars=c("mapfun_stage"), facetvar  ="actual.cgenotype", facet.ncol=1, facet.nrow=7, colorlist=allcolors)+coord_flip()
dev.off()


```

loading relevant cellinfo to gather cells for bubbleplot
```{r}


################################################################################
# create heatmap
################################################################################
# Rearrange and select conditions to emphasise different things.

recreate.heatmap.d9=T
simpleCache(paste_("cellinfo_parse", parseid), {
cellinfo}, assignToVar="cellinfo", reload=T)

gtl= adjust.markers(cellinfo, 7)$markers
cellinfo.heatmap(so, cellinfo = cellinfo, genes.to.label = gtl, assay="SCT", return.everything=T, name=Project(so), colorlist=allcolors)

simpleCache(paste_("so_parse_selected_processed_mappedWTmarkers", parseid),{
################################################################################
# get seurat markers based on mapping
################################################################################
markers.var="conditioncluster"
mapping.var="WT.clusters"
options(future.globals.maxSize = 2 * 10^9)
fullreload=F; fullrecreate=T
datte="2023-12-30" #chopstring(timestamp(""))
verbose=F
meth="deseq"
smeth="seurat"
groupvar="group1"
pvar="padj"
thresh=pval
fcvar="log_fc"
minrate=.5
minfc=1
predicted.id.thresh=0.6
replicatecol=NULL
pastedstages=paste0(includestages, collapse="-")
Project(so)=paste0("parse-", p,"-", cond, "-", includestages)
filterps(so, varbl=mapping.var, th=predicted.id.thresh)
fcat("num high quality mapped cells:",
filterps(so, varbl=mapping.var, th=predicted.id.thresh) %>% ncol )
fcat("calculating markers for mapped cells using delegate...")
so=seuratmarkers.delegate(so, group_column=markers.var, replicate_column=replicatecol, minfc=minfc, selecttop=selecttop, method=meth, getresidual=F, fullreload=F, fullrecreate=T, minrate=minrate, min.cells.per.group=10)
so
}, assignToVar="so", recreate=recreate.markers.d9, reload=!recreate.markers.d9)


simpleCache(paste_("cellinfo_parse", parseid), {
cellinfo= seriatecells(so, clusvar=markers.var, meth=smeth, clusters=allcolors[[markers.var]] %>% names  ,groupvarname=groupvar,lfcvarname=fcvar, extended.output=T, deduped=T, ncells=500)
cellinfo}, assignToVar="cellinfo", recreate=T)


```


Preparation for Supplementary Figure 7 d

```{r}


### organising conditions for  plot


h7clustered= lapply(c("C2","C4","C7","C10"), function(cll){lapply(allcolors[["actual.cgenotype"]] %>% names, function(geno){lapply(c("H7"),function(parr){  conditionclusters[grepl(paste0(cll, geno, "_", parr), conditionclusters)]  })  %>% Reduce(c,.) }) %>% Reduce(c, .) }) %>% Reduce(c, .) 

getlevels=function(nm){
  nms= allcolors[[nm]] %>% names
  if(is.null(nms)){ fcat("there are no levels defined for variable", nm)
  return(NULL)
  }else{return(nms)}}


xvar="conditioncluster"
xlevels=h7clustered %>% rev

xlabel="h7clustered" 


facetby="none"
facetlevels=getlevels(facetby)
lapply(c(2,3,4), function(num.markers){
  # 1 or 2 markers. reduce the size

levlabel="actual.cgenotype"

levs=h7clustered %>% rev

levgenelabel="h7clustered"
levsgenes=h7clustered

cellinfo.annotated0=cellinfo %>% subset.cellinfo(., levs)
cellinfo.annotated=cellinfo.annotated0 %>% add.cell.annotation(so, ., vars=c("mapfun_WT.clusters", "actual.cgenotype"))


#using markers in said clusters

gns=(cellinfo %>% subset.cellinfo(., levsgenes) %>% adjust.markers(., num.markers))$markerlist[levs] %>% Reduce(c, .) %>% rev

btab=join_meta_exp(so, genes=gns  , assay="SCT") %>% names2col(., "cellid") %>% pivot_longer(., cols=all_of(gns),names_to="gene", values_to="expression" ) %>% mutate(is.expressed=expression>0) %>%
  group_by(actual.cgenotype,mapfun_WT.clusters, conditioncluster,parental,  gene) %>% summarise(pct.expressed=sum(is.expressed)/n(), meanexp=mean(expression)) %>% as.data.frame %>%
    filter(pct.expressed>0) %>%
  mutate(conditioncc=paste0(mapfun_WT.clusters, "_", actual.cgenotype), none=1)

################################################################################
# Supplementary figure 7 d bubble plot of triaged cells across genotypes
################################################################################

sca=1.6
tpdf(path=params$outpath, paste0("bubbleplot2_topmarkers_", xlabel, "genes_from", levgenelabel, "markers_per_group_", num.markers, "facetby", facetby), he=pw*sca*0.6, wi=pw*sca+.12*length(gns))
print(ggplot(btab %>% filter(conditioncluster %in% xlevels))+geom_point(aes(x=factor(!!sym(xvar), levels=xlevels), y=factor(gene, levels=gns),size=pct.expressed, color=meanexp, alpha=pct.expressed))+theme_classic()+
        #scale_color_gradient(low="white", high="purple", guide="colourbar")+ 
      scale_color_viridis(option="D")+
        rotatex(90)+coord_flip()+facet_wrap(~get(facetby), scale="free", nrow=2))
dev.off()
})

#make figure data

fwrite(btab, file=file.path(params$plotpath, paste0("figuredata_parse_bubbleplot2", parseid, ".csv")))
```



# Appendix

Runtime: `r round(proc.time()['elapsed'] - SETUP_TIME)` seconds

Session info
```{r}
sessionInfo()
```

